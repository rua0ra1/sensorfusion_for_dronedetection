{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBFXQGKYUc4X"
      },
      "source": [
        "##### Forked from the Tensorflow's [official colab](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb) on Image Classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "1z4xy2gTUc4a"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN7G9GFmVrVY"
      },
      "source": [
        "This tutorial shows how to classify cats or dogs from images. It builds an image classifier using a `tf.keras.Sequential` model and also the functional API. You will get some practical experience and develop intuition for the following concepts:\n",
        "\n",
        "* Building _data input pipelines_ to efficiently work with data on disk to use with the model.\n",
        "* _Overfitting_ —How to identify and prevent it.\n",
        "* _Data augmentation_ and _dropout_ —Key techniques to fight overfitting in computer vision tasks to incorporate into the data pipeline and image classifier model.\n",
        "\n",
        "This tutorial follows a basic machine learning workflow:\n",
        "\n",
        "1. Examine and understand data\n",
        "2. Build an input pipeline\n",
        "3. Build the model\n",
        "4. Train the model\n",
        "5. Test the model\n",
        "6. Improve the model and repeat the process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VddxeYBEVrVZ"
      },
      "source": [
        "Let's start by importing the required packages. The `os` package is used to read files and directory structure, NumPy is used to convert python list to numpy array and to perform required matrix operations and `matplotlib.pyplot` to plot the graph and display images in the training and validation data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlchl4x2VrVg"
      },
      "source": [
        "Import Tensorflow and the Keras classes needed to construct our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Dense,\n",
        "    Conv2D,\n",
        "    Flatten,\n",
        "    Dropout,\n",
        "    MaxPooling2D,\n",
        "    BatchNormalization,\n",
        "    Add,\n",
        "    GlobalAveragePooling2D,\n",
        "    MaxPool2D,\n",
        "    ReLU\n",
        ")\n",
        "from tensorflow.keras.callbacks import (\n",
        "    ReduceLROnPlateau,\n",
        "    EarlyStopping,\n",
        "    ModelCheckpoint\n",
        ")\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPHx8-t-VrVo"
      },
      "source": [
        "Let us load the Cats vs Dogs dataset from `tfds`. We shuffle and use the first 90\\% for training and the rest for validation. The dataset contains around 20k training images of cats and dogs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEd0Tyv82Vf7"
      },
      "source": [
        "train_ds, val_ds =  tfds.load('cats_vs_dogs', as_supervised=True, shuffle_files=True, split=['train[:90%]', 'train[90%:]'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lp-0ejxOtP1"
      },
      "source": [
        "For convenience, set up variables to use while pre-processing the dataset and training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NqNselLVrWA"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 180\n",
        "IMG_WIDTH = 180"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INn-cOn1VrWC"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jfk6aSAVrWD"
      },
      "source": [
        "Format the images into appropriately pre-processed floating point tensors before feeding to the network:\n",
        "\n",
        "1. Decode contents of these images and convert it into proper grid format as per their RGB content.\n",
        "2. Convert them into floating point tensors.\n",
        "3. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcKTz4lW6mN8"
      },
      "source": [
        "def convert(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n",
        "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH]) # Resize image\n",
        "    return image, label\n",
        "\n",
        "train_batches = (\n",
        "    train_ds\n",
        "    .shuffle(512)\n",
        "    .map(convert, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        ")\n",
        "\n",
        "validation_batches = (\n",
        "    val_ds\n",
        "    .map(convert, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyexPJ8CVrWP"
      },
      "source": [
        "### Visualize training images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60CnhEL4VrWQ"
      },
      "source": [
        "Visualize the training images by extracting a batch of images from the training generator—which is 32 images in this example—then plot five of them with `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f0Z7NZgVrWQ"
      },
      "source": [
        "sample_ds = list(train_ds.take(5).as_numpy_iterator())\n",
        "sample_imgs, _ = zip(*sample_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49weMt5YVrWT"
      },
      "source": [
        "The `next` function returns a batch from the dataset. The return value of `next` function is in form of `(x_train, y_train)` where x_train is training features and y_train, its labels. Discard the labels to only visualize the training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMt2RES_VrWU"
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_VVg_gEVrWW"
      },
      "source": [
        "plotImages(sample_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5Ej-HLGVrWZ"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEgW4i18VrWZ"
      },
      "source": [
        "The model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 512 units on top of it that is activated by a `relu` activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F15-uwLPVrWa"
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI5cdkMQVrWc"
      },
      "source": [
        "### Compile the model\n",
        "\n",
        "For this tutorial, choose the *ADAM* optimizer and *binary cross entropy* loss function. To view training and validation accuracy for each training epoch, pass the `metrics` argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mg7_TXOVrWd"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YmQZ3TAVrWg"
      },
      "source": [
        "### Model summary\n",
        "\n",
        "View all the layers of the network using the model's `summary` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtny8hmBVrWh"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N06iqE8VVrWj"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oub9RtoFVrWk"
      },
      "source": [
        "Use the `fit` method to train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSF2HqhDVrWk"
      },
      "source": [
        "history = model.fit(\n",
        "    train_batches, epochs=epochs, validation_data=validation_batches\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojJNteAGVrWo"
      },
      "source": [
        "### Visualize training results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZPYT-EmVrWo"
      },
      "source": [
        "Now visualize the results after training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6oA77ADVrWp"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDnr50l2VrWu"
      },
      "source": [
        "As you can see from the plots, training accuracy and validation accuracy are off by large margin and the model has achieved only around **75-80%** accuracy on the validation set.\n",
        "\n",
        "Let's look at what went wrong and try to increase overall performance of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLO7yhLlVrWu"
      },
      "source": [
        "## Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNyx3Lp4VrWv"
      },
      "source": [
        "In the plots above, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 75-80% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable—a sign of *overfitting*.\n",
        "\n",
        "When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training examples—to an extent that it negatively impacts the performance of the model on new examples. This phenomenon is known as overfitting. It means that the model will have a difficult time generalizing on a new dataset.\n",
        "\n",
        "There are multiple ways to fight overfitting in the training process. In this tutorial, you'll use *data augmentation* and add *dropout* to our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOoVpxFwVrWy"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn_QLciWVrWy"
      },
      "source": [
        "Overfitting generally occurs when there are a small number of training examples. One way to fix this problem is to augment the dataset so that it has a sufficient number of training examples. Data augmentation takes the approach of generating more training data from existing training samples by augmenting the samples using random transformations that yield believable-looking images. The goal is the model will never see the exact same picture twice during training. This helps expose the model to more aspects of the data and generalize better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uJ1G030VrWz"
      },
      "source": [
        "### Augment and visualize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvX7hHlgVrW0"
      },
      "source": [
        "Apply the following augmentation steps: (1) random horizontal flip, (2) random rotation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWypasA9DAX6"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrKGd_jjVrW7"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images[tf.newaxis, ...], training=True)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype('uint8'))\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQGhdqHFVrXx"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Iq5TAH_VrXx"
      },
      "source": [
        "Another technique to reduce overfitting is to introduce *dropout* to the network. It is a form of *regularization* that forces the weights in the network to take only small values, which makes the distribution of weight values more regular and the network can reduce overfitting on small training examples. Dropout is one of the regularization technique used in this tutorial\n",
        "\n",
        "When you apply dropout to a layer it randomly drops out (set to zero) number of output units from the applied layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
        "\n",
        "When appling 0.1 dropout to a certain layer, it randomly kills 10% of the output units in each training epoch.\n",
        "\n",
        "Create a network architecture with this new dropout feature and apply it to different convolutions and fully-connected layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyxxXRmVVrXy"
      },
      "source": [
        "## Creating a new network with Dropouts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ba2LjtkVrXy"
      },
      "source": [
        "Here, you apply dropout to first and last max pool layers. Applying dropout will randomly set 20% of the neurons to zero during each training epoch. This helps to avoid overfitting on the training dataset. We also use the functional API to build this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fjio8EsVrXz"
      },
      "source": [
        "x = inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH ,3))\n",
        "x = data_augmentation(x, training=True)\n",
        "x = Conv2D(16, 3, padding='same', activation='relu',\n",
        "           input_shape=(IMG_HEIGHT, IMG_WIDTH ,3))(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(32, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "output = Dense(1)(x)\n",
        "model_new = tf.keras.Model(inputs, output, name=\"dropout_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpTgIxWAVrX0"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1osvc_iTVrX1"
      },
      "source": [
        "After introducing dropouts to the network, compile the model and view the layers summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkIJhS-WVrX1"
      },
      "source": [
        "model_new.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model_new.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KiDshEUVrX6"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFj0oVqVVrX6"
      },
      "source": [
        "After successfully introducing data augmentations to the training examples and adding dropouts to the network, train this new network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWxHs_luVrX7"
      },
      "source": [
        "history = model_new.fit(\n",
        "    train_batches, epochs=epochs, validation_data=validation_batches\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbdyqZdxVrYA"
      },
      "source": [
        "### Visualize the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgvF2nt7OtR7"
      },
      "source": [
        "Visualize the new model after training, you can see that there is significantly less overfitting than before. The accuracy should go up after training the model for more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BTeMuNAVrYC"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR7ES3gP5Y_d"
      },
      "source": [
        "## TODO: Create a ResNet model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MPRw57J6tfs"
      },
      "source": [
        "Implement ResNet-18 using Tensorflow's [functional API](https://www.tensorflow.org/guide/keras/functional). Fill out the functions `conv`, `residual`, and `block`. Then use them to create the ResNet model in the function `resnet`.\n",
        "\n",
        "Link to ResNet paper: [https://arxiv.org/pdf/1512.03385.pdf](https://arxiv.org/pdf/1512.03385.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B42qDPN7yon"
      },
      "source": [
        "def conv(x, filters, size, strides=1):\n",
        "    \"\"\"\n",
        "    Apply conv, batch norm, and activation to input x. Use strides > 1 to\n",
        "    downsample the output.\n",
        "    Relevant documentation:\n",
        "      - Conv2D: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "      - BatchNorm: https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n",
        "      - ReLU: https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU\n",
        "    Example:\n",
        "      x = conv(x)\n",
        "      x = batchnorm(x)\n",
        "      x = activation(x)\n",
        "      return x\n",
        "    \"\"\"\n",
        "\n",
        "    ### YOUR CODE GOES HERE ###\n",
        "\n",
        "    pass\n",
        "\n",
        "def residual(x, filters, size):\n",
        "    \"\"\"\n",
        "    Create a simple residual block as defined in the paper.\n",
        "    Example:\n",
        "      prev = x\n",
        "      x = resnet_conv(x, filters, size)\n",
        "      x = resnet_conv(x, filters, size)\n",
        "      x = Add()([prev, x])\n",
        "      return x\n",
        "    \"\"\"\n",
        "\n",
        "    ### YOUR CODE GOES HERE ###\n",
        "\n",
        "    pass\n",
        "\n",
        "def block(x, filters, size, num_blocks):\n",
        "    \"\"\"\n",
        "    Create a series of residuals of length num_blocks. This should\n",
        "    constitute the colored chain of residuals shown in Figure 3 of the\n",
        "    ResNet paper (https://arxiv.org/pdf/1512.03385.pdf)\n",
        "    Example:\n",
        "      x = conv(x, filters, size, 2)\n",
        "      for _ in range(num_blocks):\n",
        "        x = residual(x, filters, size)\n",
        "      return x\n",
        "    \"\"\"\n",
        "\n",
        "    ### YOUR CODE GOES HERE ###\n",
        "\n",
        "    pass\n",
        "\n",
        "def resnet(input_shape, name=\"resnet\"):\n",
        "    \"\"\"\n",
        "    Create the final ResNet architecture using the modular API. Make use of the\n",
        "    functions defined above (conv, residual, block). Try to implement the\n",
        "    18-layer ResNet architecture defined in Table 1 of the ResNet paper.\n",
        "    \"\"\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    ### YOUR CODE GOES HERE ###\n",
        "\n",
        "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "    return tf.keras.Model(inputs, outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz6txb6RyWG9"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJkcUqu1M6Rs"
      },
      "source": [
        "model_resnet = resnet(input_shape=[IMG_WIDTH, IMG_HEIGHT, 3])\n",
        "\n",
        "model_resnet.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "model_resnet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42vs7DJDy4W7"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTZPnAbyAjjF"
      },
      "source": [
        "callbacks = [\n",
        "            ReduceLROnPlateau(verbose=1),\n",
        "            EarlyStopping(patience=5, verbose=1),\n",
        "            ModelCheckpoint('resnet_train_{epoch}.tf',\n",
        "                            verbose=1, save_weights_only=True)\n",
        "            ]\n",
        "\n",
        "# model will stop training if validation accuracy keeps falling for 5 consecutive epochs\n",
        "history = model_resnet.fit(\n",
        "    train_batches, epochs=epochs, validation_data=validation_batches, callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmpWrRHLy9wM"
      },
      "source": [
        "### Visualize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khJp4dEGy81w"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjX7tvcQ2iS2"
      },
      "source": [
        "### Test your model on a different dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDgT1zUN2kE4"
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "test_dir = os.path.join(PATH, 'validation')\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "\n",
        "num_cats_test = len(os.listdir(test_cats_dir))\n",
        "num_dogs_test = len(os.listdir(test_dogs_dir))\n",
        "\n",
        "print('total test cat images:', num_cats_test)\n",
        "print('total test dog images:', num_dogs_test)\n",
        "\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                         directory=test_dir,\n",
        "                                                         target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                         class_mode='binary')\n",
        "\n",
        "# Change this to choose specific checkpoint weights (which gives highest validation accuracy)\n",
        "ckpt = \"resnet_train_15.tf\"\n",
        "model_resnet.load_weights(ckpt)\n",
        "\n",
        "stats = model_resnet.evaluate(\n",
        "    test_data_gen, batch_size=batch_size\n",
        ")\n",
        "print(\"test loss, test accuracy:\", stats)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}